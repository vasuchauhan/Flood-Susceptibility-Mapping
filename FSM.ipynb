{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Susceptibility Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries.\n",
    "\n",
    "1. numpy: Provides support for numerical computations, including operations on multi-dimensional arrays and matrices\n",
    "2. rasterio: A library for reading, writing, and manipulating raster geographic data (e.g., TIF files).\n",
    "3. sklearn.svm.SVC: Implements Support Vector Classification for supervised machine learning tasks.\n",
    "4. sklearn.preprocessing.MinMaxScaler: Scales data to a specified range (default: 0 to 1) for feature normalization\n",
    "5. skopt.BayesSearchCV: Performs hyperparameter optimization using Bayesian search with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to read and resize TIF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_resize_tif(tif_path, target_shape):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(\n",
    "            out_shape=(src.count, *target_shape),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "        profile = src.profile\n",
    "    return data.flatten(), profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the paths to the TIF files and then reading and resizing all TIF files into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your TIF files\n",
    "tif_files = {\n",
    "    \"Distance_from Road_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\Distance_from Road_Reclass1.tif\",\n",
    "    \"DD_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\DD_Reclass1.tif\",\n",
    "    \"Distance_from_river_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\Distance_from_river_Reclass1.tif\",\n",
    "    \"Elevation_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\Elevation_Reclass1.tif\",\n",
    "    \"LULC_Reclassify1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\LULC_Reclassify1.tif\",\n",
    "    \"NDVI_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\NDVI_Reclass1.tif\",\n",
    "    \"Slope_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\Slope_Reclass1.tif\",\n",
    "    \"SPI1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\SPI1.tif\",\n",
    "    \"TPI1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\TPI1.tif\",\n",
    "    \"TWI_Reclass1\": r\"C:\\Users\\vasuc\\Desktop\\UG Project\\Flood Susceptibility Mapping\\Data\\TWI_Reclass1.tif\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Read and resize all TIF files into a dictionary\n",
    "data = {}\n",
    "first_tif_shape = None\n",
    "for factor, path in tif_files.items():\n",
    "    try:\n",
    "        if first_tif_shape is None:\n",
    "            # Determine the target shape based on the first TIF file\n",
    "            first_tif_data, _ = read_and_resize_tif(path, (100, 100))\n",
    "            first_tif_shape = first_tif_data.shape\n",
    "        data[factor], _ = read_and_resize_tif(path, (100, 100))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or resizing TIF file for factor `{factor}`: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a placeholder target variable (replace this with your actual labels if available)\n",
    "num_samples = min(data[key].shape[0] for key in data)\n",
    "y = np.random.randint(2, size=num_samples)  # Binary classification, replace with your actual labels\n",
    "\n",
    "# Trim data to have the same number of samples\n",
    "for key in data:\n",
    "    data[key] = data[key][:num_samples]\n",
    "\n",
    "# Stack data into a single array\n",
    "X = np.stack([data[factor] for factor in tif_files.keys()], axis=1)\n",
    "\n",
    "# Scale features to a given range using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Distance_from Road_Reclass1: 0.0844\n",
      "DD_Reclass1: 0.0575\n",
      "Distance_from_river_Reclass1: 0.1413\n",
      "Elevation_Reclass1: 0.0006\n",
      "LULC_Reclassify1: 0.0235\n",
      "NDVI_Reclass1: 0.0237\n",
      "Slope_Reclass1: 0.1527\n",
      "SPI1: 0.1821\n",
      "TPI1: 0.0014\n",
      "TWI_Reclass1: 0.3328\n"
     ]
    }
   ],
   "source": [
    "# Define your SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Define the parameter grid for Bayesian optimization\n",
    "paramgrid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Define the Bayesian optimization method\n",
    "cv = BayesSearchCV(\n",
    "    estimator=svm_classifier,\n",
    "    search_spaces=paramgrid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_iter=10,  # Number of iterations for optimization\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available CPUs\n",
    ")\n",
    "\n",
    "# Fit the Bayesian optimization method\n",
    "cv.fit(X_scaled, y)\n",
    "\n",
    "# Get the best SVM classifier after optimization\n",
    "best_svm_classifier = cv.best_estimator_\n",
    "\n",
    "# Get feature importance scores (weights) from the optimized SVM classifier\n",
    "weights = np.abs(best_svm_classifier.coef_.flatten()) / np.sum(np.abs(best_svm_classifier.coef_))\n",
    "\n",
    "# Print weights of each factor\n",
    "for factor, weight in zip(tif_files.keys(), weights):\n",
    "    print(f\"{factor}: {weight:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
